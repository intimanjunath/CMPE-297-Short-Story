# Inside LLM Agents: How AI Workers Plan, Remember, and Act in the Real World â€” Overview

Repository for the analysis and presentation of the survey  
**â€œLarge Language Model Agent: A Survey on Methodology, Applications and Challengesâ€ (Luo et al., 2025)**.  
This repo collects my written summary, presentation slides, and key takeaways about how LLM agents are built, evaluated, and where they can fail.

---

## Paper Description

The Luo et al. survey looks at **LLM agents** not just as clever chatbots, but as systems that can **observe, plan, act with tools, and learn over time**. Instead of treating the model as the whole application, it decomposes an agent into:

- how we **construct** a single agent (profile, memory, planning, action),
- how agents **collaborate** with each other (centralized, decentralized, hybrid),
- and how agents **evolve** (self-learning, co-evolution, external feedback).

The paper also reviews **benchmarks, metrics, tools, and real-world issues** such as security, privacy, and social impact. Overall, itâ€™s a 2025 snapshot of where LLM agents are today and whatâ€™s still missing before we can trust them in real workflows.

---

## What I Did in This Project

This project turns that dense survey into a compact â€œshort storyâ€ for practitioners:

- Framed LLM agents as a simple **loop**: _observe â†’ plan â†’ act â†’ reflect_.
- Highlighted the four core architecture pieces: **profile, memory, planning, tools**.
- Pulled out what **benchmarks and ablation studies** actually say about performance  
  (e.g., what breaks when you remove memory, tools, or explicit planning).
- Summarized **security, privacy, and social impact** issues for agents that can call real tools.
- Created:
  - a **Medium article**,
  - a **slide deck**,
  - and a **video presentation** explaining these ideas.

---

## Architecture at a Glance

- **Agent Construction**
  - *Profile definition* â€“ role and goals of the agent  
  - *Memory mechanism* â€“ short-term context, long-term skills, retrieval (RAG / graphs)  
  - *Planning capability* â€“ task decomposition, search over plans, feedback loops  
  - *Action execution* â€“ tool APIs, code runners, web/DB access, robots/simulators  

- **Agent Collaboration**
  - *Centralized control* â€“ a coordinator agent delegating tasks  
  - *Decentralized collaboration* â€“ peer agents negotiating and sharing work  
  - *Hybrid architectures* â€“ mixes of manager + specialist agents  

- **Agent Evolution**
  - *Self-learning* â€“ reflection, self-correction, prompt and policy updates  
  - *Multi-agent co-evolution* â€“ agents improving each other via debate or feedback  
  - *External resources* â€“ human feedback, new tools, and updated knowledge bases  

These bullets are my distilled version of the taxonomy figure from the survey.

---

## Read / Watch

- **Medium article**  
  _Inside LLM Agents: How AI Workers Plan, Remember, and Act in the Real World_  
  ðŸ‘‰ https://medium.com/@manjunatha.inti/inside-llm-agents-how-ai-workers-plan-remember-and-act-in-the-real-world-c68be59836f1

- **Slides (PDF)**  
  ðŸ‘‰ `slides/Inside-LLM-Agents-How-AI-Workers-Plan-Remember-and-Act-in-the-Real-World.pdf`

- **Paper (arXiv PDF)**  
  ðŸ‘‰ https://arxiv.org/pdf/2503.21460.pdf

- **YouTube presentation (15+ min)**  
  ðŸ‘‰ _TODO: add YouTube link here_

- **SlideShare deck**  
  ðŸ‘‰ _TODO: add SlideShare link here_

---

## Acknowledgments

All technical claims, diagrams, and taxonomy descriptions are based on:

> **Luo, J. et al. (2025). _Large Language Model Agent: A Survey on Methodology, Applications and Challenges._ arXiv:2503.21460.**

Iâ€™m grateful to the authors for providing a comprehensive and up-to-date survey of LLM agent research.

---


> Inti, M. (2025). _Inside LLM Agents: How AI Workers Plan, Remember, and Act in the Real World._ Medium article and accompanying slide deck.
